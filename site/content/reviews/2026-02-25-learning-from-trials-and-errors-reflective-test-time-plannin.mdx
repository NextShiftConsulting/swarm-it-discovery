---
title: "Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs"
date: "2026-02-25"
source: "arxiv"
arxivId: "2602.21198v1"
paperUrl: "https://arxiv.org/abs/2602.21198v1"
pdfUrl: "https://arxiv.org/pdf/2602.21198v1.pdf"
authors: ['Yining Hong', 'Huang Huang', 'Manling Li', 'Li Fei-Fei', 'Jiajun Wu']
similarityScore: 0.324
matchedTopics: ['Mechanistic Interpretability']
tags: ['mechanistic-interpretability', 'llm', 'cs-lg', 'learning']
excerpt: "Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than..."
---


# Learning from Trials and Errors: Reflective Test-Time Planning for Embodied LLMs


## Overview

This paper presents research in the area of cs.LG.

**Abstract Summary:**
Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: reflection-in-action, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflec...

The work shows a **32% similarity** to our research interests in Mechanistic Interpretability.

Further analysis pending manual review.

## Paper Details

- **Authors:** Yining Hong, Huang Huang, Manling Li, Li Fei-Fei, Jiajun Wu et al.
- **Published:** 2026-02-24
- **Source:** [arxiv](https://arxiv.org/abs/2602.21198v1)
- **PDF:** [Download](https://arxiv.org/pdf/2602.21198v1.pdf)

## Abstract

> Embodied LLMs endow robots with high-level task reasoning, but they cannot reflect on what went wrong or why, turning deployment into a sequence of independent trials where mistakes repeat rather than accumulate into experience. Drawing upon human reflective practitioners, we introduce Reflective Test-Time Planning, which integrates two modes of reflection: reflection-in-action, where the agent uses test-time scaling to generate and score multiple candidate actions using internal reflections before execution; and reflection-on-action, which uses test-time training to update both its internal reflection model and its action policy based on external reflections after execution. We also include retrospective reflection, allowing the agent to re-evaluate earlier decisions and perform model updates with hindsight for proper long-horizon credit assignment. Experiments on our newly-designed Long-Horizon Household benchmark and MuJoCo Cupboard Fitting benchmark show significant gains over baseline models, with ablative studies validating the complementary roles of reflection-in-action and reflection-on-action. Qualitative analyses, including real-robot trials, highlight behavioral correction through reflection.

---

*This analysis was automatically generated by the Swarm-It research discovery pipeline.
Similarity score: 32% match to our research topics.*
